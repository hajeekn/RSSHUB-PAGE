
---
title: '如何看待目前国内「隐私计算」行业现状，市场发展有哪些趋势？'
categories: 
 - 社交媒体
 - 知乎
 - 知乎热榜
headimg: 'https://picsum.photos/400/300?random=4139'
author: 知乎
comments: false
date: Fri, 04 Mar 2022 13:31:51 GMT
thumbnail: 'https://picsum.photos/400/300?random=4139'
---

<div>   
知安局的回答<br><br><p data-pid="1J9cX0Z9">谢邀，利益相关：阿里安全小二一名，“猎豹”作者之一。</p><p data-pid="NHBsy22H"> “隐私计算”这个名词我们也不知道怎么来的，它其实是一个我国独有的名词，英文中没有严格对应的词组。按最接近的英文Privacy-enhancing computation直译的话，或许叫“隐私增强计算”更合适？不过字儿少了也就容易上口，更利于传播。</p><p data-pid="FARHLeqX"> 目前隐私计算是一大类技术的统称，包括安全多方计算，同态加密，差分隐私，可信执行环境(机密计算)，联邦学习等。这些技术的共同目的是要做到“数据可用不可见”。</p><p data-pid="wHfxiF5V"> 什么是“可用不可见”？我们知道数据是可以拷贝的，如果数据所有者把数据给其他人使用，那么别人自然也就可以拷贝数据，摇身一变成为下一个数据所有者。这明显会侵害原来的数据所有者的权益和隐私。隐私计算正是为解决这一问题而生：任何对数据的需求最后都会落到一个具体的使用场景上，隐私计算可以让数据使用者只能按照具体场景拿到使用结果，而不是拿走数据本身。</p><p data-pid="feUKJO-S"> 一个最简单的例子是“百万富翁问题”：假设两个富翁各自存了一笔钱，他们想知道谁的钱更多，但是又不想把自己到底有多少钱透露给任何人。在没有“隐私计算”时，显然这是不可能实现的：任一方要独立的计算比较结果，都必须要接触输入数据。但是隐私计算可以让这成为可能：我们可以设计对应的隐私计算解决方案，让双方合作的计算出“比较”这个结果(即“可用”)，而不需要把财富数字告诉对方(即“不可见”)。具体的，我们可以使用基于混淆电路或秘密共享的安全多方计算方法来解决这个百万富翁问题。</p><p data-pid="fh45QHqE"> “猎豹”就是这样一种安全两方计算技术。假设这样一种场景，甲方拥有源数据(例如图片)，乙方拥有AI模型(例如可以判断图片是否违规或者侵权)。甲希望购买乙的服务来智能的判断自己的数据是否有问题，但是双方的数据都是商业机密，甲不愿意把自己的图图直接交给乙，乙也不愿意直接把自己的模型参数告诉甲。“猎豹”就可以完美的满足这么一个纠结的需求，让双方可以合作算出图片是否违规(可用)，同时甲无法获取乙的模型参数，乙也不知道甲的图图到底是什么(不可见)。</p><p data-pid="usUaPXKq"> 需要说明的是，以安全多方计算这一类技术为代表的隐私计算解决方案，需要引入复杂的密码学算法和协议来实现“可用不可见”，因此其代价是巨大的。比如上面的图片识别的例子，“猎豹”需要至少80秒才能完成一次ResNet50的推理，如果乙直接把甲的图片拿去做明文推理，可能只需要毫秒级，这个差距达到了数千倍。在简单一些的模型上，这个差距会缩小一些，但代价也不少，例如逻辑回归训练，“猎豹”可以在百兆网下，数小时内完成百万行的数据建模。</p><p data-pid="biQOdsRC"> 为什么安全多方计算这么昂贵呢？因为它是一种密码学协议，需要能够以数学证明的方式说明自己除了双方认可的计算结果之外，不会泄露其他任何关于原始数据的信息。这就是“可证明安全”。</p><p data-pid="R8wi89-D">如果不需要可证明安全，那么其实可以设计各种千奇百怪的方案：例如百万富翁问题，双方先比亿位，再比千万位，相等就比下一位，一直比到有一个人胜出，不就行了吗？这不也没泄露具体的财富数字么？不是的，这还泄露了额外的信息：双方在哪一位上不相等。这方面的对比就是联邦学习：联邦学习不是纯加密状态下的计算，因此其各个数据所有者之间的交互中是必然含有额外信息的。即使使用了同态加密，其交互中也必然包含解密步骤。以两方合作的联邦学习为例，其中拥有同态私钥一方可以通过解密结果，获取另一方的中间信息内容，而这部分信息显然是最终建模结果之外的额外信息。这些额外信息算不算隐私泄露？可能各人有各种看法，但是如果方案涉及重要的敏感数据，我们更建议使用可证明安全，确定没有问题的方案，而不是不可证安全，不确定有没有问题的方案。</p><p data-pid="RclWTQtM">当前我国隐私计算业界实际上存在一个误区，就是关注性能超过关注安全性，拿到一个隐私计算解决方案，大家习惯先问“这个方案能做到比明文慢多少倍”。实际上从上面的例子里我们可以看到，只有在同样的可证明安全模型的基础上，才可以比较性能。我们说“猎豹”比世界最好成果提升5倍，这就是和微软研究院的CryptFLOW2（ACM CCS 2020）在同样的半诚实两方模型下比较得来的。英雄惜英雄，“猎豹”发表的第二天就在国际业界形成了相当大的影响力（捂脸，诚实地夸一下寄几）：CryptFLOW2的作者来信恭喜我们完成对他们的超越，ABY2.0（USENIX’Sec 21）的作者来信埋怨我们为什么不引用他，最有趣的是MP-SPDZ（ACM CCS2020）的作者来信质疑我们怎么可以这么快，挑战我们的代码某处写的有问题，最后来回论战了十几封邮件之后，他没能挑战成功 ：）相比之下，如果不要求可证明安全，我相信不用说5倍，快几百倍都可以做出来，但是这样的成果没有任何技术难度，是不可能得到相关领域专家的认可的。</p><p data-pid="Zb2z0n2M"> 随着隐私计算概念的火热，我国业界目前确实存在不少赶热点的项目，都自称“隐私计算”解决方案，但是其中很多都是不可证安全的，门槛很低。如果这种状态持续下去，“隐私计算”可能会泡沫化，用户会错误的高估隐私计算的性能，低估隐私计算的局限性，劣币会驱逐良币，泡沫最终会破灭，对业界会形成不利的影响。我们团队这次把“猎豹”开源出来也是希望业界能够确实了解隐私计算的难度、代价，对可证明安全方案的性能有一定的体感。期待学术界和工业界一起合作，打造更好的隐私计算生态！</p>  
</div>
            