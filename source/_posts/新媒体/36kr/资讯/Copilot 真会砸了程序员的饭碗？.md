
---
title: 'Copilot 真会砸了程序员的饭碗？'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://picsum.photos/400/300?random=1486'
author: 36kr
comments: false
date: Thu, 15 Jul 2021 12:17:58 GMT
thumbnail: 'https://picsum.photos/400/300?random=1486'
---

<div>   
<p>最近OpenAI与GitHub联合构建的AI自动编程工具Copilot正式登场！Copilot基于自然语言处理模型GPT-3搭建而成，可在程序员编写代码时提供建议，甚至直接补齐代码。</p> 
<p>目前Copilot预览版已经正式上线Visual Studio Code平台。虽然Copilot AI码自动生成器仍在逐渐完善当中，但它的出现却提供了一个关于大型自然语言处理模型的发展思路，也让我们程序员群体和对于自身未来是否会被AI取代的问题，产生深深的思考。</p> 
<h2><strong>初识OpenAI的GPT-3</strong></h2> 
<p>在2019年DOTA2的顶级赛事TI8的正赛完成之后，OpenAI的人工智能战队与TI8的冠军OG举行了一场表演赛，在英雄阵容限定17个，部分道具和功能禁用的前提下，OpenAI以2：0完胜了OG，尤其值得一提的是第二场比赛仅用时15分钟OpenAI就把OG斩落马下，这一系列的精彩表现也让OpenAI在业界抱得大名。</p> 
<p>后来OpenAI开始转战自然语言处理领域，他们第一个引发广泛关注的模型是GPT-2。2019年底著名魔幻电视剧集《权利的游戏》的最后一季上演了史诗级的烂尾，不过网友用GPT-2来重写剧本而<a class="project-link" data-id="95377" data-name="得到" data-logo="https://img.36krcdn.com/20200929/v2_fcdf767846d041309970adf0877fc666_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/95377" target="_blank">得到</a>的新结局，却意外得到了全网的普遍好评，这也让GPT-2顺利出圈。</p> 
<p>去年的六月初，OpenAI发布了全新一代的NLP模型——GPT-3（论文地址：https://arxiv.org/abs/2005.14165），这个模型的效果之好已经到了令人叹为观止的程度，在笔者的印象中GPT-3一直在GitHub的趋势榜的榜首位置上，且一直霸榜了两个月（https://github.com/openai/gpt-3），一时之间各类GPT-3的神奇应用层出不穷。GPT-3的出现再次证明了AI领域大力出奇迹的现象，这个模型的数据集达到了45TB，参数个数1750亿，训练成本接近500万美元。</p> 
<p>与之前NLP领域的王者BERT模型不同，GPT-3虽然博采众长，但从本质上讲GPT-3还是个自回归模型，通俗的理解自回归就是使用自身做回归变量的过程。比如在见到一个时间序列“我爱北京天安门”，那自回归模型要完成的任务就是收到“我爱北京天”这段输入时，将后面的内容补齐。</p> 
<p>假设我们天、安、门三段日志分别对应X_1、X_2、X_3，那么如果我们要建模”天安门”这段主义序列时，就要通过<a class="project-link" data-id="589309" data-name="贝叶斯" data-logo="https://img.36krcdn.com/20200729/v2_3e4a9eb8875b4556a708d3af6562cfcb_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/589309" target="_blank">贝叶斯</a>公式解出，在在所有语料信息中，“天安门”这个序列出现的联合概率分布 P(X_1,X_2,X_3)。由于这些概率分布彼此之间并不独立的，我们仅统计P(X_1)、P(X_2)、P(X_3)三个概率是不够的。因为X_1还依赖于其它变量存在条件分布 P(X_2|X_1) 和 P(X_3|X_1)。对于X_2和X_3也是一样，我们可以将这三个模型组合起来获得期望联合分布 P(X_1,X_2,X_3)=P(X_1)P(X_2|X_1)P(X_3|X_1,X_2)。在自回归模型中都考虑了顺序信息，也就是说他看到“天安”之后极有可能续写出后面的“门”来，这样的条件概率算法是自回归模型的基础。也就是说GPT-3，一旦看到“天安”这个输入之后，就能判断出后面是“门”字的概率大幅度增加，因此从原理上看GPT-3的确更适合做文本的生成与续写工作。</p> 
<h2><strong>误打误撞，Copilot成GPT-3的首个商业应用</strong></h2> 
<p>在去年GPT-3最火的阶段，代码补全这个应用虽然也被业界关注，但其热度根本不够看，当时像对话机器人、自动诊断、自动作诗、自动作曲的应用才是比较吸引眼球的，即使是在编程方面，代码补全的应用也没有到大放异彩的程度，早在去年7月上线的那个能根据需求直接生成前端代码的debuid.co，都曾经被认为是AI编程的未来趋势。</p> 
<p>不过GPT-3的知识储备虽然丰富，但本质上却还是对以往代码的模仿，很难有创造性的灵动表现，在很多情况下GPT-3无法独立完成创作。因此与人类程序员配合，由人类程序员完成功能模块的一部分，再由AI帮助续写剩余代码，似乎成为了一个相当合理的选择，在这样的背景下Copilot就应运而生了。</p> 
<p>Copilot使用的Codex深度学习模型，就是基于GPT-3的编程任务微调版本，它以部分完成的代码及注释作为输入，输出完整的代码建议。Copilot的官方网站（https://t.co/eWPueAXTFt ）将其描述为“程序员结对编程实践中的AI对手”，笔者看到不少参加初测的网友都提到，很多时候提供函数签名，Copilot就可以完成整个函数的代码编写了，有时甚至只需要一个简单的注释描述，Copilot就能把整个功能模块全写出来。</p> 
<p>神经网络非常擅长从大型训练数据集中得到有效的发现与建议，从这个角度来看，使用GPT-3的微调版本，帮助程序员在GitHub的源代码库寻找解决方案的做法，有着非常大的意义。</p> 
<h2><strong>前途虽光明，但道路依旧曲折</strong></h2> 
<p>根据GitHub官方说法来看，如果Copilot技术预览成功，Copilot的商业版本也将很快问世。我们知道目前程序员的时薪很高，一般从10美元到150美元之间，只要能节省几个小时的编程时间或稍稍提高一些开发速度，就能产生不低的效益。尤其是对于一些有着丰富经验的程序员来说，Copilot意味着更加容易的跨界，在它的加持下Rust将不会那么劝退，C++也不会再那么令人爱恨交加。而且Copilot需要定期更新和微调，这对于GitHub这样的开源公司来说还会带来持续性的收入，AI编码未来很可能会成为一个价值数十亿美元的产业，不过光明的前途不意味着Copilot的发展将一帆风顺，从目前情况来看，其主要问题有以下几点：</p> 
<p>不分许可证的引用代码是否涉嫌侵权？正如前文所说GPT-3能够成功依靠就是海量的训练集，根据Copilot的主页显示，Codex的训练代码由公开来源的英语注释及源代码而来，这其中包括 了GitHub上公共存储库中的源代码及注释，而有迹象表明Codex用于训练的代码，并没有按照不同的开源许可证进行区分对待。</p> 
<p>我们知道Copilot未来肯定要有商业版本推出，那么问题就来了，如果Copilot将那些已经明确不允许用于商业用途的代码，通通拿来进行AI训练的话，这种做法是否涉嫌侵权？针对这个问题网上已经有很多不同的声音了，笔者认为如果AI最终给出的建议代码与原先训练集中的代码一模一样的话，那么这种情况肯定会涉嫌侵权，但建议代码与原训练代码的相似度如何判断才是关键所在，当然截止目前这还依旧是个开放性问题，业界尚未形成共识。</p> 
<p>无效建议拖慢开发效率：根据GitHub给出的官方说法Copilot试图理解程序员的意图，并尽可能生成最好的代码，但它建议的代码可能并不总是有效，甚至没有意义。也有不少程序员亲测后反馈说，如果想提高Copilot建议的正确率，你就必须按照其他程序员那样，使用一个<a class="project-link" data-id="3969555" data-name="大众" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3969555" target="_blank">大众</a>化的代码风格以及变量名、函数名的命名规范，如果你的代码规范和变量命名都特别有个性，那么你得到的建议很可能会是没有意义的代码。</p> 
<p>归根结底Copilot等模型根本就不理解源代码的目的和结构，更不了解程序运行的目的，他能做的就是高度模仿之前大量存在过的类似代码，因此他给出的结果很可能是没有意义的，如果这些无效建议的比例过高，会使程序员的编程思路混乱，甚至拖慢开发的节奏。</p> 
<p>引用老旧类库，增加安全风险：笔者注意到GitHub还警告说，Copilot可能会建议旧的或者不推荐使用的类库和代码，这可能会导致安全问题。正如前文所言，Copilot本质上是对历史上全部代码的学习与模仿，但是从实操来讲，你又很难对如此大量的代码进行有效标注，因此即便Copilot的建议即使有效而且能够正常运行，也不能代表这些代码没有安全漏洞，这样的特性就使得开发人员完全审查AI生成的代码变得非常重要。</p> 
<p>可以说AI自动化编码工具的发展还远远没有达到我们的期望，程序员在使用Copilot时必须时刻小心翼翼，你不能把Copilot这样的AI自动生成工具当成不会出错的编程机器。如果由于工期紧迫，而完全依赖Copilot提供代码，不去进行安全审核的话，那么Copilot带来的风险很可能比产生的效益还大。</p> 
<p>不过无论如何Copilot前途还是非常光明的，从历史经验来看，新的编程工具必然带来新的编程风险。我们必须仔细跟AI自动编程这个新领域的发展趋势，才能做到不落后于趋势，也不引入风险。</p> 
<p>本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号<a target="_blank" rel="noopener noreferrer" href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&mid=2650855588&idx=2&sn=35b5dc07b0f72ad54a30c73cd4ffbf7a&chksm=bd58a9778a2f206104325f7ae8847646e60e89dc6d0f3c0b8ffb506f9024f26521dacf44f5d4&scene=27#wechat_redirect">“CSDN”（ID：CSDNnews）</a>，作者：马超，，责编：孙胜，36氪经授权发布。</p>  
</div>
            