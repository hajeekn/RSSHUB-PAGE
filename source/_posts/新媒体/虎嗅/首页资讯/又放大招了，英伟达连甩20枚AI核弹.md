
---
title: '又放大招了，英伟达连甩20枚AI核弹'
categories: 
 - 新媒体
 - 虎嗅
 - 首页资讯
headimg: 'https://img.huxiucdn.com/article/content/202203/23/075403604719.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
author: 虎嗅
comments: false
date: Wed, 23 Mar 2022 01:12:00 GMT
thumbnail: 'https://img.huxiucdn.com/article/content/202203/23/075403604719.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85'
---

<div>   
<p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/KtbJD1oWEadpMHK-s3XHaA" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">芯东西（ID：aichip001）</span></a><span class="text-remarks">，作者：ZeR0，原文标题：《英伟达连甩20枚AI核弹！800亿晶体管GPU、144核CPU来了》，题图来自：Nvidia GTC</span></p><p>芯东西3月23日凌晨报道，今日，NVIDIA<span class="text-remarks" label="备注">（英伟达）</span>携基于最新Hopper架构的H100 GPU系列新品高调回归。</p><p>英伟达创始人兼CEO黄仁勋依然穿着皮衣，不过这次他没有出现在几乎已成GTC大会“标配”的厨房场景中，而是在一个更具科幻感的虚拟空间。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075403604719.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="555" src="https://img.huxiucdn.com/article/content/202203/23/075403604719.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>延续以往风格，黄仁勋在主题演讲中继续秒天秒地秒空气，公布多个“全球首款”。这次他带来一系列堪称“地表最强”的AI重磅新品，<strong>随便一个精度的AI性能，都比上一代A100高出3~6倍</strong>。</p><p>虽然英伟达并购Arm的计划刚刚告吹，但它的数据中心“三芯”总路线<span class="text-remarks" label="备注">（GPU+DPU+CPU）</span>依然不动摇——继去年推出其首款数据中心CPU后，今天，英伟达又亮出一款基于Arm架构的Grace CPU超级芯片。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075405919021.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202203/23/075405919021.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>此外，黄仁勋再次派出自己的虚拟数字人化身“玩偶老黄”Toy Jensen，并跟这个表情生动的玩偶进行了一番流畅的实时问答对话。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075415333220.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202203/23/075415333220.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>凭借押中图形处理和人工智能两大赛道，英伟达已经成为全球半导体市值TOP1。截至文章发布时间，<strong>英伟达的市值超过6600亿美元，比第二名台积电足足多了近1100亿美元</strong>。</p><p>下面就让我们来看看本场GTC大会的完整干货：</p><p><strong>1. H100 GPU</strong>：采用台积电4N工艺，拥有800亿个晶体管，实现了首个GPU机密计算，相比A100，FP8性能提升6倍，FP16、TF32、FP64性能各提升3倍。</p><p><strong>2. 全新NVLink Switch系统</strong>：高度可扩展，支持256块H100 GPU互连。</p><p><strong>3. 融合加速器H100 CNX</strong>：耦合H100 GPU与ConnectX-7和以太网智能网卡，可为I/O密集型应用提供更强劲的性能。</p><p><strong>4. DGX H100</strong>：配备8块H100 GPU，总计有6400亿个晶体管，在全新的FP8精度下AI性能比上一代高6倍，可提供900GB/s的带宽。</p><p><strong>5. DGX SuperPOD</strong>：最多由32个DGX H100组成，AI算力可达1EFLOPS。</p><p><strong>6. Eos超级计算机</strong>：全球运行速度最快的AI超级计算机，配备576台DGX H100系统，FP8算力达到18EFLOPS，PF64算力达到275PFLOPS。</p><p><strong>7. Grace CPU超级芯片</strong>：由两个CPU芯片组成，采用最新Armv9架构，拥有144个CPU核心和1TB/s的内存带宽，将于2023年上半年供货。</p><p><strong>8. 为定制芯片集成开放NVLink</strong>：采用先进封装技术，与英伟达芯片上的PCIe Gen 5相比，能源效率高25倍，面积效率高90倍。英伟达还将支持通用小芯片互连传输通道UCIe标准。</p><p><strong>9. CUDA-X</strong>：60多个针对CUDA-X的一系列库、工具和技术的更新。</p><p><strong>10. Riva 2.0</strong>：对话式AI服务Riva全面发行，2.0版本支持识别7种语言，可将神经文本转换为不同性别发声的语音。</p><p><strong>11. Merlin 1.0</strong>：可帮助企业快速构建、部署和扩展先进的AI推荐系统。</p><p><strong>12. Sionna</strong>：一款用于6G通信研究的AI框架。</p><p><strong>13. OVX与OVX SuperPod</strong>：面向工业数字孪生的数据中心级服务器和超级集群。</p><p><strong>14. Spectrum-4</strong>：全球首个400Gbps端到端网络平台，交换吞吐量比前几代产品高出4倍，达到51.2Tbps。</p><p><strong>15. Omniverse Cloud</strong>：支持协作者们随时随地实现远程实时协同工作。</p><p><strong>16. DRIVE Hyperion 9</strong>：汽车参考设计，拥有14个摄像头、9个雷达、3个激光雷达和20个超声传感器，总体传感器数量是上一代的两倍。</p><p><strong>17. DRIVE Map</strong>：多模态地图引擎，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。</p><p><strong>18. Clara Holoscan MGX</strong>：可供医疗设备行业在边缘开发和部署实时AI应用的计算平台，AI算力可达每秒254~610万亿次运算。</p><p><strong>19. Isaac for AMR</strong>：提供自主移动机器人系统参考设计。</p><p><strong>20. Jetson AGX Orin开发者套件</strong>：在边缘实现服务器级的AI性能。</p><p>黄仁勋还介绍了英伟达创建的NVIDIA AI加速计划，通过与AI生态系统中的开发者合作，开发工程化解决方案，以确保客户放心部署。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075416210547.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202203/23/075416210547.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><h3 label="大标题" class="text-big-title">一、H100 GPU：800亿晶体管、六大创新<br></h3><p>每次英伟达的GPU新架构都会以一位科学家的名字来命名，这次同样如此。</p><p>新Hopper架构的命名取自美国计算机科学家格蕾丝·赫柏<span class="text-remarks" label="备注">（Grace Hopper）</span>，她是耶鲁大学第一位数学女博士、世界上第三位程序员、全球首个编译器的发明者，也是第一个发现“bug”的人。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075417580705.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="772" label="图片备注" src="https://img.huxiucdn.com/article/content/202203/23/075417580705.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">格蕾丝·赫柏正在教学COBOL编程语言<br></p><p>1945年9月9日，格蕾丝使用的Mark Ⅱ机出现故障，经过近一天的排查，她找到了故障的原因：继电器中有一只死掉的蛾子。后来，“bug”<span class="text-remarks" label="备注">（小虫）</span>和“debug”<span class="text-remarks" label="备注">（除虫）</span>这两个词汇就作为计算机领域的专用词汇流传至今。</p><p>基于Hopper架构的一系列AI计算新品，被冠上各种“全球首款”。按行业惯例，但凡比较AI算力，必会拿英伟达最新旗舰GPU作为衡量标准。</p><p>英伟达也不例外，先“碾压”一下自己两年前发布的上一代A100 GPU。</p><p><strong>作为全球首款基于Hopper架构的GPU，英伟达 H100接过为加速AI和高性能计算<span class="text-remarks" label="备注">（HPC）</span>扛旗的重任，FP64、TF32、FP16精度下AI性能都达到A100的3倍。</strong></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075417672991.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202203/23/075417672991.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>可以看到，NVIDIA越来越热衷于走稀疏化路线。过去六年，英伟达相继研发了使用FP32、FP16进行训练的技术。此次H100的性能介绍又出现了新的Tensor处理格式FP8，而FP8精度下的AI性能可达到4PFLOPS，约为A100 FP16的6倍。</p><p>从技术进展来看，H100有6项突破性创新：</p><p><strong>1. 先进芯片</strong>：H100采用台积电4N工艺、台积电CoWoS 2.5D封装，有800亿个晶体管<span class="text-remarks" label="备注">（A100有540亿个晶体管）</span>，搭载了HBM3显存，可实现近5TB/s的外部互联带宽。</p><p>H100是首款支持PCIe 5.0的GPU，也是首款采用HBM3标准的GPU，单个H100可支持40Tb/s的IO带宽，实现3TB/s的显存带宽。黄仁勋说，20块H100 GPU便可承托相当于全球互联网的流量。</p><p><strong>2. 新Transformer引擎</strong>：该引擎将新的Tensor Core与能使用FP8和FP16数字格式的软件结合，动态处理Transformer网络的各个层，在不影响准确性的情况下，可将Transformer模型的训练时间从数周缩短至几天。</p><p><strong>3. 第二代安全多实例GPU</strong>：MIG技术支持将单个GPU分为7个更小且完全独立的实例，以处理不同类型的作业，为每个GPU实例提供安全的多租户配置。H100能托管7个云租户，而A100仅能托管1个，也就是将MIG的部分能力扩展了7倍。每个H100实例的性能相当于两个完整的英伟达云推理T4 GPU。</p><p><strong>4. 机密计算</strong>：H100是全球首款具有机密计算功能的GPU加速器，能保护AI模型和正在处理的客户数据，可以应用在医疗健康和金融服务等隐私敏感型行业的联邦学习，以及共享云基础设施。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075419085079.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="522" src="https://img.huxiucdn.com/article/content/202203/23/075419085079.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p><strong>5. 第4代英伟达NVLink</strong>：为了加速大型AI模型，NVLink结合全新外接NVLink Switch，可将NVLink扩展为服务器间的互联网络，最多连接多达256个H100 GPU，相较于上一代采用英伟达 HDR Quantum InfiniBand网络，带宽高出9倍。</p><p><strong>6. DPX指令</strong>：Hopper引入了一组名为DPX的新指令集，DPX可加速动态编程算法，解决路径优化、基因组学等算法优化问题，与CPU和上一代GPU相比，其速度提升分别可达40倍和7倍。</p><p>总体来说，H100的这些技术优化，将对跑深度推荐系统、大型AI语言模型、基因组学、复杂数字孪生、气候科学等任务的效率提升非常明显。</p><p>比如，用H100支持聊天机器人使用的monolithic Transformer语言模型Megatron 530B，吞吐量比上一代产品高出30倍，同时能满足实时对话式AI所需的次秒级延迟。</p><p>再比如用H100训练包含3950亿个参数的混合专家模型，训练速度可加速高达9倍，训练时间从几周缩短到几天。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075420806460.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="555" src="https://img.huxiucdn.com/article/content/202203/23/075420806460.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p><strong>H100将提供SXM和PCIe两种规格，可满足各种服务器设计需求。</strong></p><p>其中H100 SXM提供4 GPU和8 GPU配置的HGX H100服务器主板；H100 PCIe通过NVLink连接两块GPU，相较PCIe 5.0可提供7倍以上的带宽。PCIe规格便于集成到现有的数据中心基础设施中。</p><p>这两种规格的电力需求都大幅增长。H100 SXM版的散热设计功耗<span class="text-remarks" label="备注">（TDP）</span>达到700W，比A100的400W高出75%。据黄仁勋介绍，H100采用风冷和液冷设计。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075420709410.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="529" src="https://img.huxiucdn.com/article/content/202203/23/075420709410.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>这款产品预计于今年晚些时候全面发售。阿里云、AWS、百度智能云、谷歌云、微软Azure、Oracle Cloud、腾讯云和火山引擎等云服务商均计划推出基于H100的实例。</p><p>为了将Hopper的强大算力引入主流服务器，英伟达推出了全新的融合加速器H100 CNX。它将网络与GPU直接相连，耦合H100 GPU与英伟达ConnectX-7 400Gb/s InfiniBand和以太网智能网卡，使网络数据通过DMA以50GB/s的速度直接传输到H100，能够避免带宽瓶颈，为I/O密集型应用提供更强劲的性能。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075422916112.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="534" src="https://img.huxiucdn.com/article/content/202203/23/075422916112.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><h3 label="大标题" class="text-big-title">二、更强企业级AI系统，全球最快AI超算<br></h3><p>基于A100，英伟达最先进的企业级AI基础设施DGX H100系统、DGX POD、DGX SuperPOD以及一一登场。它们将从今年第三季度开始供应。</p><p>黄仁勋称，<strong>在财富10强企业和100强企业中，分别有8家和44家企业使用DGX作为AI基础架构。</strong></p><p>英伟达DGX系统现在包含英伟达AI Enterprise软件套件，该套件新增了对裸金属基础设施的支持。DGX客户可使用软件套件中的预训练AI平台模型、工具包和框架来加快工作速度。</p><p><strong>1. DGX H100：最先进的企业级AI基础设施</strong></p><p>第四代英伟达DGX系统DGX H100是一款基于英伟达H100 Tensor Core GPU的AI平台。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075422343255.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="505" src="https://img.huxiucdn.com/article/content/202203/23/075422343255.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>每个DGX H100系统配备8块H100 GPU，总计有6400亿个晶体管，由NVLink连接，在全新的FP8精度下AI性能可达32Petaflops，比上一代系统性能高6倍。</p><p>DGX H100系统中每块GPU都通过第四代 NVLink连接，可提供900GB/s的带宽，是上一代系统的1.5倍。DGX H100的显存带宽可达24TB/s。</p><p>该系统支持双x86 CPU，每个系统还包含2个英伟达BlueField-3 DPU，用于卸载、加速和隔离高级网络、存储及安全服务。</p><p>8个英伟达ConnectX-7 Quantum-2 InfiniBand网卡能够提供400GB/s的吞吐量，可用于连接计算和存储，这一速度比上一代系统提升了1倍。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075423673553.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="553" src="https://img.huxiucdn.com/article/content/202203/23/075423673553.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p><strong>2. DGX SuperPOD：FP8 AI性能达1Exaflops</strong></p><p>DGX H100系统是新一代英伟达DGX POD和DGX SuperPOD超级计算机的构建模块。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075424380749.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202203/23/075424380749.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>借助NVLink Switch系统，拥有32个节点、256个GPU的DGX Pod，其HBM3显存达20.5TB，显存带宽高达768TB/s。</p><p>“相比之下，整个互联网不过只有100TB/s。”黄仁勋感慨道。每个DGX都可借助4端口光学收发器连接到NVLink Switch，每个端口都有8个100G-PAM4通道，每秒能够传输100GB，32个NVLink收发器连接到1个机架单元的NVLink Switch系统。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075426405098.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="546" src="https://img.huxiucdn.com/article/content/202203/23/075426405098.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>新一代DGX SuperPOD可提供1Exaflops的FP8 AI性能，比上一代产品性能高6倍，能够运行具有数万亿参数的大型语言模型工作负载；还有20TB的HBM3显存、192TFLOPS的SHARP网络计算性能。</p><p>通过采用Quantum-2 InfiniBand连接及NVLink Switch系统，新DGX SuperPOD架构在GPU之间移动数据的带宽高达70TB/s，比上一代高11倍。</p><p>Quantum-2 InfiniBand交换机芯片拥有570亿个晶体管，能提供64个400Gbps端口。多个DGX SuperPOD单元可组合使用。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075428700918.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="534" src="https://img.huxiucdn.com/article/content/202203/23/075428700918.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>此外，英伟达推出新的DGX-Ready托管服务计划，以助力简化AI部署。其DGX Foundry托管的开发解决方案正在全球扩展，北美、欧洲和亚洲的新增地点支持远程访问DGX SuperPOD。</p><p>DGX Foundry中包含英伟达Base Command软件，该软件能够使客户基于DGX SuperPOD基础设施，轻松管理端到端AI开发生命周期。</p><p><strong>3. Eos：全球运行速度最快的AI超算</strong></p><p>黄仁勋还透露说，英伟达正在打造Eos超级计算机，并称这是“首个Hopper AI工厂”，将于数月后推出。</p><p>该超算包含18个DGX POD、576台DGX H100系统，共计4608块DGX H100 GPU，预计将提供18.4Exaflops的AI算力，<strong>这比目前运行速度最快的日本富岳<span class="text-remarks" label="备注">（Fugaku）</span>超级计算机快4倍</strong>。在传统科学计算方面，Eos预计可提供275 Petaflops的性能。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075429312473.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="545" src="https://img.huxiucdn.com/article/content/202203/23/075429312473.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><h3 label="大标题" class="text-big-title">三、由两个CPU组成的超级芯片</h3><p>除了GPU外，英伟达数据中心“三芯”战略中另一大支柱CPU也有新进展。</p><p>今日，英伟达推出首款面向HPC和AI基础设施的基于Arm Neoverse的数据中心专属CPU——Grace CPU超级芯片。</p><p>这被黄仁勋称作“AI工厂的理想CPU”。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075437435509.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="562" src="https://img.huxiucdn.com/article/content/202203/23/075437435509.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>据介绍，Grace Hopper超级芯片模组能在CPU与GPU之间进行芯片间的直接连接，其关键驱动技术是内存一致性芯片之间的NVLink互连，每个链路的速度达到900GB/s。</p><p><strong>Grace CPU超级芯片也可以是由两个CPU芯片组成。它们之间通过高速、低延迟的芯片到芯片互连技术NVLink-C2C连在一起。</strong></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075438933318.png?imageView2/2/w/1000/format/png/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202203/23/075438933318.png?imageView2/2/w/1000/format/png/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>它基于最新的Armv9架构，单个socket拥有144个CPU核心，具备最高的单线程核心性能，支持Arm新一代矢量扩展。</p><p>在SPECrate®2017_int_base基准测试中，Grace CPU超级芯片的模拟性能得分为740，据英伟达实验室使用同类编译器估算，这一结果相比当前DGX A100搭载的双CPU高1.5倍以上。</p><p>此外，Grace CPU超级芯片可实现当今领先服务器芯片内存带宽和能效的2倍。</p><p>其依托带有纠错码的LPDDR5x内存组成的创新的内存子系统，能实现速度和功耗的最佳平衡。LPDDR5x内存子系统提供两倍于传统DDR5设计的带宽，可达到1TB/s，同时功耗也大幅降低，CPU加内存整体功耗仅500瓦。 </p><p>Grace CPU超级芯片可运行所有的英伟达计算软件栈，结合英伟达ConnectX-7网卡，能够灵活地配置到服务器中，或作为独立的纯CPU系统，或作为GPU加速服务器，可以搭配1块、2块、4块或8块基于Hopper的GPU。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075440936001.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202203/23/075440936001.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>也就是说，用户只维护一套软件栈，就能针对自身特定的工作负载做好性能优化。</p><p>黄仁勋说，Grace超级芯片有望明年开始供货。</p><h3 label="大标题" class="text-big-title">四、为定制芯片集成开放NVLink，将支持UCIe小芯片标准</h3><p>我们单独来说一下NVLink-C2C技术。</p><p>前面说的Grace CPU超级芯片系列、去年发布的Grace Hopper超级芯片都采用了这一技术来连接处理器芯片。</p><p>NVIDIA超大规模计算副总裁Ian Buck认为：“为应对摩尔定律发展趋缓的局面，必须开发小芯片和异构计算。”</p><p>因此，英伟达利用其在高速互连方面的专业知识开发出统一、开放的NVLink-C2C互连技术。</p><p>该技术将支持定制裸片与英伟达GPU、CPU、DPU、NIC和SoC之间实现一致的互连，从而通过小芯片构建出新型的集成产品，助力数据中心打造新一代的系统级集成。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075440659265.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="554" src="https://img.huxiucdn.com/article/content/202203/23/075440659265.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p><strong>NVLink-C2C现已为半定制芯片开放，支持其与NVIDIA技术的集成。</strong></p><p>通过采用先进的封装技术，英伟达NVLink-C2C互连链路的能效最多可比NVIDIA芯片上的PCIe Gen 5高出25倍，面积效率高出90倍，可实现每秒900GB乃至更高的一致互联带宽。</p><p>NVLink-C2C支持Arm AMBA一致性集线器接口（AMBA CHI）协议，或CXL工业标准协议，可实现设备间的互操作性。当前英伟达和Arm正在密切合作，以强化AMBA CHI来支持与其他互连处理器完全一致且安全的加速器。</p><p>NVIDIA NVLink-C2C依托于英伟达的SERDES和LINK设计技术，可从PCB级集成和多芯片模组扩展到硅插入器和晶圆级连接。这可提供极高的带宽，同时优化能效和裸片面积效率。</p><p><strong>除NVLink-C2C之外，NVIDIA还将支持本月早些时候发布的通用小芯片互连传输通道UCIe标准。</strong></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075441914209.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="829" label="图片备注" src="https://img.huxiucdn.com/article/content/202203/23/075441914209.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p label="图片备注" class="text-img-note">UCIe标准<br></p><p>与NVIDIA芯片的定制芯片集成既可以使用UCIe标准，也可以使用NVLink-C2C，而后者经过优化，延迟更低、带宽更高、能效更高。</p><h3 label="大标题" class="text-big-title">五、AI软件：对话式AI服务全面发行，推荐系统AI框架1.0版本</h3><p>如今英伟达已经能提供全栈AI，除了AI计算硬件外，其AI软件也有不少进展。</p><p>黄仁勋说，AI已经从根本上改变了软件的能力以及开发软件的方式，过去十年，英伟达加速计算在AI领域实现了百万倍的加速。</p><p>今日，英伟达发布了60多个针对CUDA-X的一系列库、工具和技术的更新，以加速量子计算和6G研究、网络安全、基因组学、药物研发等领域的研究进展。</p><p>英伟达将使用其首台AI数字孪生超级计算机Earth-2来应对气候变化挑战，并创建了Physics-ML模型来模拟全球天气模式的动态变化。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075446265251.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="567" src="https://img.huxiucdn.com/article/content/202203/23/075446265251.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>英伟达还与来自加州理工学院、伯克利实验室等高校及科研机构的研究人员们开发了一个天气预报AI模型FourCastNet，该模型基于10TB的地球系统数据进行训练，首次在降水预测上达到比先进的数值模型更高的准确率，并使预测速度提高了4~5个数量级。<strong>以前，传统的数值模拟需要一年时间，而现在只需几分钟。</strong></p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075447674125.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="563" src="https://img.huxiucdn.com/article/content/202203/23/075447674125.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>NVIDIA Triton是一款开源的、超大规模的模型推理服务器，是AI部署的“中央车站”，它支持CNN、RNN、GNN、Transformer等各种模型、各类AI框架及各类机器学习平台，支持在云、本地、边缘或嵌入式设备运行。</p><p>同时，黄仁勋宣布英伟达对话式AI服务Riva全面发行，Riva 2.0版本支持识别7种语言，可将神经文本转换为不同性别发声的语音，用户可通过其TAO迁移学习工具包进行自定义调优。</p><p><strong>Maxine是一个AI模型工具包，现已拥有30个先进模型，可优化实时视频通信的视听效果。</strong>比如开远程视频会议时，Maxine可实现说话者与所有参会者保持眼神交流，并能将说的语言实时切换成另一种语言，而且音色听起来不变。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075448559987.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="458" src="https://img.huxiucdn.com/article/content/202203/23/075448559987.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>本次GTC发布的版本增加了用于回声消除和音频超分辨率的新模型。</p><p>此外，黄仁勋也宣布推出英伟达面向推荐系统的AI框架Merlin的1.0版本。</p><p>Merlin可帮助企业快速构建、部署和扩展先进的AI推荐系统。比如，微信用Merlin将短视频推荐延迟缩短为原来的1/4，并将吞吐量提升了10倍。从CPU迁移至GPU，腾讯在该业务上的成本减少了1/2。</p><p>在医疗健康领域，黄仁勋谈道，过去几年，AI药研初创公司获得了超400亿美元的投资，数字生物学革命的条件已经成熟，他称这将是“NVIDIA AI迄今为止最伟大的使命”。</p><p>6G标准于2026年左右问世，一些相关基础技术逐渐成形。对此，黄仁勋宣布推出了一款用于6G通信研究的AI框架Sionna。</p><p><i>六、</i>Omniverse：首推数字孪生，专用服务器和超级集群</p><p>黄仁勋认为，<strong>第一波AI学习是感知和推理，下一波AI的发展方向是机器人，也就是使用AI规划行动。</strong>英伟达Omniverse平台也正成为制造机器人软件时必不可少的工具。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075449326837.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="564" src="https://img.huxiucdn.com/article/content/202203/23/075449326837.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>作为虚拟世界的仿真引擎，Omniverse平台能遵循物理学定律，构建一个趋真的数字世界，可以应用于使用不同工具的设计师之间的远程协作，以及工业数字孪生。</p><p>黄仁勋认为，工业数字孪生需要一种专门构建的新型计算机，因此英伟达打造了面向工业数字孪生的OVX服务器和OVX SuperPOD超级集群。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075450817775.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="554" src="https://img.huxiucdn.com/article/content/202203/23/075450817775.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>OVX是首款Omniverse计算系统，由8个英伟达A40 RTX GPU、3个ConnectX-6 200Gbps网卡<span class="text-remarks" label="备注">（NIC）</span>和2个英特尔至强Ice Lake CPU组成。</p><p>32台OVX服务器可构成OVX SuperPOD超级集群，实现这一连接的关键设施是英伟达今日新推出的Spectrum-4以太网平台。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075454073555.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="553" src="https://img.huxiucdn.com/article/content/202203/23/075454073555.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>据悉，这是全球首个400Gbps端到端网络平台，其交换吞吐量比前几代产品高出4倍，聚合ASIC带宽达到51.2Tbps，支持128个400GbE端口。</p><p>Spectrum-4实现了纳秒级计时精度，相比典型数据中心毫秒级抖动提升了5~6个数量级。这款交换机还能加速、简化和保护网络架构。与上一代产品相比，其每个端口的带宽提高了2倍，交换机数量减少到1/4，功耗降低了40%。</p><p><strong>该平台由英伟达Spectrum-4交换机系列、ConnectX-7智能网卡、BlueField-3 DPU和DOCA数据中心基础设施软件组成，可提高AI应用、数字孪生和云基础架构的性能和可扩展性，大幅加速大规模云原生应用。</strong></p><p>Spectrum-4 ASIC和SN5000交换机系列基于4nm工艺，有1000亿个晶体管，并经过简化的收发器设计，实现领先的能效和总拥有成本。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075454300037.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="559" src="https://img.huxiucdn.com/article/content/202203/23/075454300037.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>Spectrum-4可在所有端口之间公平分配带宽，支持自适应路由选择和增强拥塞控制机制，能显著提升数据中心的应用速度。</p><p>Spectrum-4 ASIC具有12.8Tbp加密带宽和领先的安全功能，例如支持MACsec和VXLANsec，并通过硬件信任根将安全启动作为默认设置，帮助确保数据流和网络管理的安全性和完整性。</p><p>现在各大计算机制造商纷纷推出OVX服务器，对于想在OVX试用Omniverse的客户，英伟达在全球多地提供LaunchPad计划，第一代OVX正由英伟达和早期客户运行，第二代OVX正被构建中。Spectrum-4的样机将在今年第四季度末发布。</p><p>随后，曾在往届GTC大会展示过的黄仁勋虚拟化身“玩偶老黄”Toy Jensen再度现身。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075456158227.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="667" data-h="372" src="https://img.huxiucdn.com/article/content/202203/23/075456158227.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>它不是录像，而能做到完全实时地进行眼神交流与对话。黄仁勋现场问它“什么是合成生物学”、“你是如何制作出来的”等问题，它都对答如流。</p><p>使用英伟达Omniverse Avatar框架，企业就能快速构建和部署像Toy Jensen这样的虚拟形象，从模仿声音到细微的头部及身体运动，乃至高保真度的形象塑造，都让虚拟人更加灵动。</p><p>最后，得益于Riva中的最新对话式AI技术和超大语言模型Megatron 530B NLP，虚拟人可以听懂你问的问题，也能跟你实时聊天互动。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075457313513.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="555" src="https://img.huxiucdn.com/article/content/202203/23/075457313513.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>在此基础上，英伟达宣布将推出Omniverse Cloud。通过Omniverse Cloud连接，协作者们使用英伟达RTX PC、笔记本电脑和工作站，均可实现远程实时协同工作。</p><p>用户如果没有RTX计算机，只需点击一下，即可从GeForce Now上启动Omniverse。</p><h3 label="大标题" class="text-big-title">七、汽车：预告DRIVE Hyperion 9，推出多模态地图引擎</h3><p>Omniverse平台是整个工作流程的核心，DRIVE平台则相当于AI司机。</p><p>黄仁勋宣布下一代DRIVE Hyperion 9将从2026年起搭载到汽车中，它将拥有14个摄像头、9个雷达、3个激光雷达和20个超声传感器，总体传感器数量将是Hyperion 8的两倍。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075457460206.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="556" src="https://img.huxiucdn.com/article/content/202203/23/075457460206.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>此外，英伟达推出了一种多模态地图引擎NVIDIA DRIVE Map，包含摄像头、激光雷达和雷达的数据，同时兼顾安全性。</p><p><strong>DRIVE Map有两个地图引擎，真值测绘地图引擎和众包车队地图引擎。</strong>黄仁勋谈道，到2024年，他们预计绘制并创建北美、西欧和亚洲所有主要公路的数字孪生，总长度约为50万公里。</p><p>“我们正在构建地球级别的自动驾驶车队数字孪生。”黄仁勋说。</p><p>合作方面，全球第二大电动汽车制造商比亚迪将在2023年上半年开始投产的汽车中搭载DRIVE Orin计算平台。自动驾驶独角兽企业元戎启行、中国自动驾驶创企云骥智行也宣布将在其L4级自动驾驶车规级量产方案中搭载NVIDIA DRIVE Orin SoC芯片。</p><p>美国电动汽车公司Lucid Motors、中国L4级自动驾驶科技公司文远知行、中国新型电动车公司悠跑科技均宣布将应用英伟达DRIVE Hyperion自动驾驶汽车平台。</p><h3 label="大标题" class="text-big-title">八、机器人平台：从医疗设备到自主移动机器人</h3><p>黄仁勋认为下一波AI浪潮是机器人，英伟达正在构建多个机器人平台，包括用于自动驾驶汽车的DRIVE、用于操纵和控制系统的Isaac、用于自主式基础架构的Metropolis、用于医疗设备的Holoscan等。</p><p>他将机器人系统的工作流程简化为真值数据生成、AI模型训练、Omniverse数字孪生、机器人技术栈四大支柱。</p><p>Clara Holoscan MGX是一个开放可扩展的机器人平台，其设计符合IEC-62304医疗级规格，核心计算机为Jetson AGX Orin和ConnectX-7智能网卡，并可选配NVIDIA RTX A6000 GPU。</p><p>该平台<strong>AI算力可达每秒254~610万亿次运算</strong>，目前向早期体验客户开放，正式上市时间是5月，并将于2023年第一季度完成医疗级准备。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075458782675.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="543" src="https://img.huxiucdn.com/article/content/202203/23/075458782675.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><p>Metropolis平台的下载量已经达到30万次，拥有1000多个生态系统合作伙伴，并在超过100万个设施中运营。</p><p>机器人发展最快的领域之一是自主移动机器人<span class="text-remarks" label="备注">（AMR）</span>，它本质上是室内无人驾驶，速度偏低但环境高度非结构化。</p><p>今天，英伟达推出Isaac for AMR，它有四大核心：用于真值生成的NVIDIA DeepMap、用于训练模型的NVIDIA AI、搭载Orin的AMR机器人参考设计、Isaac机器人技术堆栈中的新Gem及基于Omniverse的新版Isaac Sim，每个都单独可用且完全开放。</p><p>与DRIVE Hyperion类似，Isaac Nova是一个AMR机器人系统参考设计，整个Isaac堆栈都基于此构建。Nova有2个摄像头、2个激光雷达、8个超声波雷达和4个鱼眼摄像头。</p><p>英伟达还宣布推出Jetson Orin开发者套件，以在边缘实现服务器级的AI性能。</p><p>Nova AMR将于第二季度上市，它将配备英伟达新的DeepMap雷达制图系统，可以扫描和重建环境，以进行路线规划和数字孪生仿真。</p><p class="img-center-box"><img class="lazyImg" _src="https://img.huxiucdn.com/article/content/202203/23/075459247415.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" data-w="1000" data-h="529" src="https://img.huxiucdn.com/article/content/202203/23/075459247415.jpg?imageView2/2/w/1000/format/jpg/interlace/1/q/85" referrerpolicy="no-referrer"></p><h3 label="大标题" class="text-big-title">九、结语：AI开发者的前沿技术盛宴</h3><h3 label="大标题" class="text-big-title"></h3><p>这些年来，英伟达GTC大会已经成为一场面向AI、HPC、科学计算、数字孪生及自动驾驶等诸多前沿领域的技术盛宴。</p><p>在这场盛宴中，我们不仅看到技术突破如果改变各行各业的生产效率和工作方式，也看到英伟达围绕计算世界的最新布局。</p><p>随着新一代大规模云技术的出现，数据中心架构有待转型。在稳拥GPU基本盘的基础之上，英伟达的角色正从图形显示和加速计算“偏科学霸”，转向围绕数据中心三大芯片支柱全面发展。</p><p>黄仁勋认为，<strong>数据中心正在转变成“AI工厂”</strong>，它通过处理海量的数据来实现智能，而今日推出的H100便是实现企业AI业务加速的引擎。</p><p>H100的多项技术创新，数据中心专属Grace CPU超级芯片的特殊设计，以及AI和Omniverse平台的持续升级，进一步扩大了英伟达在加速AI训练及推理领域的领导地位。</p><p>在为期4天的英伟达GTC大会上，我们还将看到更多不同细分领域的专家，分享他们如何利用AI和加速计算领域的技术创新，来开展各类开创性的研究或解决正面临的挑战。</p><p><span class="text-remarks" label="备注">本文来自微信公众号：</span><a href="https://mp.weixin.qq.com/s/KtbJD1oWEadpMHK-s3XHaA" target="_blank" rel="nofollow" style="text-decoration: none;"><span class="text-remarks">芯东西（ID：aichip001）</span></a><span class="text-remarks">，作者：ZeR0</span></p>  
</div>
            