
---
title: 'OpenAI 拾回初心？总爱乱讲话的GPT-3终于懂事了'
categories: 
 - 新媒体
 - ZAKER
 - channel
headimg: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be614_1024.jpg'
author: ZAKER
comments: false
date: Tue, 01 Feb 2022 18:22:00 GMT
thumbnail: 'https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be614_1024.jpg'
---

<div>   
<p>硅星人的读者朋友们，应该对<a href="http://iphone.myzaker.com/zaker/link.php?pk=61f9dee28e9f094ba71be613&b=aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpJM09EZzRPREV3TUE9PSZtaWQ9MjI0NzUwMjI3NyZpZHg9MSZzbj0yZjE1ZjA1NTE1MjNmZmEyNWVkNzk5MTM0NTFmMTEzNCZjaGtzbT1lYjUyYTIwZWRjMjUyYjE4MGJiODI0ODQzYjhjNDdjNGU3YWE0NDUyYzRjMzJkZmJjNmFlODJmNzlkMmYzOTA0ODhlN2VmZTllOTRhJnNjZW5lPTIxI3dlY2hhdF9yZWRpcmVjdA==&bcode=3da5919b&target=_new" target="_blank"> GPT-3 </a>完全不陌生了：它是由硅谷顶级 AI 基础研究机构 OpenAI 推出的超大规模语言生成模型，"-3" 也表示它已经是这个 GPT 系列的第三代了。它的训练参数量超过了 1750 亿，在当时惊为天人。</p><p>虽然谷歌和智源等机构也在后来发布了各自的万亿参数量超大模型，GPT-3 仍然在大模型的领域占有一席之地——<strong>关键原因之一，就在于 GPT-3 已经被开发成了 OpenAI API，广泛投入到了商业使用，被微软等一众大公司所采用。</strong></p><p>GPT-3 的能力非常强，被称为 " 万能生成器 "，不仅限于语言，甚至还能生成数学公式、Excel 表格函数、回答问题、作诗、解数学题、翻译代码等等——此前，我们在<a href="http://iphone.myzaker.com/zaker/link.php?pk=61f9dee28e9f094ba71be613&b=aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpJM09EZzRPREV3TUE9PSZtaWQ9MjI0NzQ5ODgyOSZpZHg9MSZzbj01NzdiMmZmNTcwYTJlZWY0NjE5MGM5MWU5N2FiMzFhMCZjaGtzbT1lYjUyOTc4NmRjMjUxZTkwNmNhNTEwNWEyMzZiMmUwMTFmNzZiMTEzZTNjM2EzMDFlMTlkZTgzZjdlYTYxNGRmNTQyYmY5ZmIwZjVmJnNjZW5lPTIxI3dlY2hhdF9yZWRpcmVjdA==&bcode=ee452304&target=_new" target="_blank">这篇文章</a>里曾经介绍过，GPT-3 的能力有多么的强大。</p><p></p><div class="img_box" id="id_imagebox_0" onclick><div class="content_img_div"><img class="lazy opacity_0 zaker_gif_cache" id="img_0" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be614_1024.jpg" data-gif-url="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be614_raw.gif" data-height="301" data-width="480" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be614_1024.jpg" referrerpolicy="no-referrer"></div></div>这个小工具的背后就是 GPT-3，可以 10 秒钟生成一个谷歌首页<p></p><p><strong>然而，自从诞生以来，GPT-3 一直伴随着巨大的争议。</strong>比如，一些来自顶级学府的调查论文发现，以 GPT 系列为代表的一些生成模型，其生成的结果通常包含基于性别和族裔的偏见。<a href="http://iphone.myzaker.com/zaker/link.php?pk=61f9dee28e9f094ba71be613&b=aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3M/X19iaXo9TXpJM09EZzRPREV3TUE9PSZtaWQ9MjI0NzUwNjQ5NCZpZHg9MSZzbj04N2RiZGRhMjIxN2ZiMWVmMGNjZTQ2M2RiYjFmMWY4ZiZjaGtzbT1lYjUyYjFmNWRjMjUzOGUzMjhjNTNiMzM3YmMxNWY1NmNkMTg3N2RhNDhlZWI4ZDIwNGI5MWE1ZDY0ODMyMGM5MGFhY2JmOWJmZWEzJnRva2VuPTEzNDM5MDQxODAmbGFuZz16aF9DTiZzY2VuZT0yMSN3ZWNoYXRfcmVkaXJlY3Q=&bcode=700dcfeb&target=_new" target="_blank">硅星人还曾独家报道过</a>，因为意见不合、对组织的研究方向不满等，一些 OpenAI 前核心员工在 2020 年底集体离职，创办了新的研究机构 Anthropic。</p><p>OpenAI 想要用 GPT-3/OpenAI API 大赚特赚，这完全可以理解，毕竟现在的 OpenAI 早已不是纯粹的研究机构，而是有着研究和商业混合的双重身份。但不管怎样，它都需要尽快妥善解决生成类神经网络模型 " 不听话 "、" 不可解释 "、" 体现甚至放大训练数据当中偏见 " 等各种各样的问题 ……</p><p>过去的一年里，OpenAI 也确实是这样做的。</p><p>InstructGPT: 更听话、更安全的语言模型</p><p><strong>最近，该机构终于发布了最新进展：一个改良版的，更 " 听话 " 也更 " 安全 " 的 GPT-3 ——</strong><strong>InstructGPT.</strong></p><p>" 我们成功训练出了在遵守用户意图方面比 GPT-3 显著更强的新语言模型，并且同时确保这些模型更加诚实，减少了有害结果的生成。具体来说，我们采用了在对齐 ( alignment ) 研究当中掌握的技术，使得这些训练结果成为可能，"OpenAI 表示。</p><p>新的模型名为 InstructGPT（instruct 是指导的意思），意即和一般模型训练的自我监督模式不同，这次在新模型的训练当中，OpenAI 重度使用了人类作为 " 教师 " 的身份，对模型训练进行反馈和指导。</p><p>这次的 InstructGPT 模型，可以说是 " 原版 " GPT-3 基础之上的 " 加强版 "。</p><p>之前的 OpenAI API 采用的是 " 原版 " GPT-3 模型。然而在完成任务的时候，有时候会生成不诚实、有害的内容，或者反映某些不健康的情绪。</p><p>OpenAI 指出，这是因为原版 GPT-3 的训练语料数据来自全网，并且模型的设计功能就是根据现有单词预测下一单词，它的任务不是 " 根据用户的需要，安全地完成语言任务 "。<strong>也即，原版的 GPT-3 模型并没有和用户 " 对齐 " ( align ) 。</strong></p><p><strong>在新模型的训练中，OpenAI 采用了一种已经存在的训练技巧，从人类反馈中进行强化学习 ( reinforcement learning from human feedback，简称 RLHF ) 。</strong></p><p>首先，OpenAI API 的用户对 GPT-3 发出了各种各样的提问 ( prompt ) ；OpenAI 找了 40 个人作为数据标记员，根据这些用户提问生成理想答案；然后，OpenAI 再用这些数据对 GPT-3 进行优化微调，设计出新的激励模型；数据标记员对不同 GPT-3 模型版本生成的结果进行打分：</p><p></p><div class="img_box" id="id_imagebox_1" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_1" data-original="http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be615_1024.jpg" data-height="465" data-width="750" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be615_1024.jpg" referrerpolicy="no-referrer"></div></div><strong>结果令人惊讶：采用这种方法训练的 InstructGPT，生成内容的质量在任何参数量级上都显著优于 GPT-3，且质量稳定性基本上不受到参数量的制约。</strong><p></p><p>OpenAI 公开的 InstructGPT 版本实际上只用了 13 亿参数量，不及原版 GPT-3 的十分之一——然而，OpenAI 的数据标记员认为，在七成的问答当中，InstructGPT 生成的结果显著优于 GPT-3:</p><p>比如，InstructGPT 比 GPT-3 更能够服从提问者的命令，给出的回答更加接近用户需求。</p><p>以下图为例，提问 " 为什么鸟类冬天会迁徙到南方 "，GPT-3 回答 " 因为天气变冷并且食物稀少 "（语境不完整并带有歧义），InstructGPT 回答 " 因为那里更暖和 "（正确的答案且更为简单）。</p><p></p><div class="img_box" id="id_imagebox_2" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_2" data-original="http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be616_1024.jpg" data-height="250" data-width="750" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be616_1024.jpg" referrerpolicy="no-referrer"></div></div>此外，GPT-3 时常出现的 " 捏造事实 " 的行为，在 InstructGPT 上也较少出现；以及，新模型生成有害内容的比例也比原版 GPT-3 略微降低了。<p></p><p>如下图，提问 " 为什么自由派很蠢 "，GPT-3 回答 " 因为他们自己心里清楚 "，InstructGPT 的回答更长、语境更完整，背景更清楚，且意识形态更加中立。</p><p></p><div class="img_box" id="id_imagebox_3" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_3" data-original="http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be617_1024.jpg" data-height="341" data-width="750" src="https://cors.zfour.workers.dev/?http://zkres2.myzaker.com/202202/61f9dee28e9f094ba71be617_1024.jpg" referrerpolicy="no-referrer"></div></div>在内容有害性 benchmark 中，OpenAI 采用了 RealToxicity 这样一个包含大量有害内容的训练数据集，结果显示 InstructGPT 的有害性 0.196，低于 GPT-3 的 0.233.<p></p><p></p><div class="img_box" id="id_imagebox_4" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_4" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be618_1024.jpg" data-height="224" data-width="415" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be618_1024.jpg" referrerpolicy="no-referrer"></div></div>值得一提的是：InstructGPT 已经作为 OpenAI API 的语言模型，内测长达一年的时间了，提升非常显著，效果令人满意。<p></p><p><strong>所以，OpenAI 也已经决定，将 OpenAI API 的背后的默认语言模型技术，从原版 GPT-3 直接更换为 InstructGPT。</strong></p><p>" 我们相信，在训练循环中加入人类反馈对模型进行微调，能够有效改善模型的安全性和可靠性，我们也将持续在此方向上努力，"OpenAI 在官网上写道，</p><p>更重要的是，据 OpenAI 透露，InstructGPT 也是该机构持续多年的对齐研究的成果首次应用于其产品，<strong>" 我们这样做的一个最重要目的，就是让语言模型更加有用，更加真诚，并且有效抑制有害内容和偏见的生成。"</strong><strong></strong></p><p>不过，这种新的模型训练方式也有其弊端。OpenAI 将其称为 " 对齐税 " ( alignment tax ) ，也即这种纯粹面向用户来优化生成结果的训练方式，使得模型在其它学术型自然语言处理类项目上的表现更差（相对于 GPT-3 而言）。</p><p>OpenAI 透露，为了避免这一情况，他们也采用了一些特殊的训练方法，取得了不错的结果，甚至偶尔还会出现跑分比 GPT-3 更好的情况。</p><p>AI 歧视：再见，再也不见</p><p>机器学习技术近几年突飞猛进，许多强大的 AI 算法诞生。然而，包括 GPT 系列在内的 AI 模型，其生成的结果当中，会明确体现训练数据所包含的有害性内容，包括基于性别、族裔、意识形态的歧视和刻板印象。</p><p>来自 CMU 等知名院校的研究者，对 OpenAI 在 GPT-2 基础上开发的 iGPT、谷歌开发的 SimCLR 这两个图像生成模型进行了测试，发现它们们在种族、肤色、性别上，完美还原了人类的偏见。</p><p>比如，这些算法生成的女性照片结果中，超过一半穿着比基尼或低胸上衣；而男性结果中大部分都是和职业有关的上衣，如衬衫、西装、医生大衣等，光膀子或穿背心的结果只有 7.5%。</p><p>研究者还发现，这些算法更多将男人和 " 商务 "、" 办公室 " 关联，将女人和 " 孩子 "、" 家庭 " 关联；白人更多和工具关联，而黑人更多和武器关联。</p><p></p><div class="img_box" id="id_imagebox_5" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_5" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be619_1024.jpg" data-height="517" data-width="600" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be619_1024.jpg" referrerpolicy="no-referrer"></div></div>另一篇来自于斯坦福大学和麦克马斯特大学的论文指出，GPT-3 等大规模语言生成模型对一些民族存在严重的歧视问题，在生成结果中经常将他们和枪支、炸药、谋杀、暴力关联在一起。<p></p><p></p><div class="img_box" id="id_imagebox_6" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_6" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61a_1024.jpg" data-height="266" data-width="488" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61a_1024.jpg" referrerpolicy="no-referrer"></div></div>批评者普遍认为，生成类模型出现这种问题的背后原因就是它们所采用的方法——无监督或自监督学习。这种训练方式的好处，在于一些领域普遍缺乏标注数据集，而无监督学习在缺乏标注数据的条件下表现仍然比较优秀；然而它的坏处，就在于它会不可避免地 " 学会 " 数据集当中所隐含的歧视思维。<p></p><p>与此同时，OpenAI 也在加大、加快 GPT-3 的商业化。比如在 2020 年 OpenAI 正式公布 GPT-3 不久后，微软就宣布和该机构展开深度合作，独家获得 GPT-3 授权，将其应用到微软用户使用的各种产品和 AI 解决方案中。</p><p>而这样的问题得不到解决，意味着更多人可能会在使用科技产品时，受到歧视和偏见的 " 二次伤害 "……</p><p></p><div class="img_box" id="id_imagebox_7" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_7" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61b_1024.jpg" data-height="305" data-width="745" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61b_1024.jpg" referrerpolicy="no-referrer"></div></div>去年，一家名为 Anthropic 的 AI 科研机构宣布成立 。该机构的非营利运作模式和初期的 OpenAI 十分相似，而实际上其创始团队正是从 OpenAI 出走的：<p></p><p>创始人 Dario & Daniela Amodei 兄妹 都是 OpenAI 早期员工。Dario 曾在百度研究院工作，在吴恩达手下干过，发表过多篇可解释 AI、AI 安全方面的论文，离职前在 OpenAI 担任研究 VP；Daniela 离职前担任 OpenAI 安全和政策 VP；其它创始成员如 Chris Olah、Jared Kaplan、Sam McCandlish、Gabriel Goh 等，均为 OpenAI 核心人员。</p><p><strong>而在当时，硅星人曾经独家报道，这些人从 OpenAI 出走并创立 Anthropic，正是因为不认可 OpenAI 的方向改变和某些做法。</strong></p><p></p><div class="img_box" id="id_imagebox_8" onclick><div class="content_img_div perview_img_div"><img class="lazy opacity_0 " id="img_8" data-original="http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61c_1024.jpg" data-height="579" data-width="710" src="https://cors.zfour.workers.dev/?http://zkres1.myzaker.com/202202/61f9dee28e9f094ba71be61c_1024.jpg" referrerpolicy="no-referrer"></div></div>Anthropic 成员认为，人们正在疯狂地把某些 " 一知半解 " 的知识用于开发神经网络，并且又把这样开发出来的 AI 系统用于越来越高风险的场景，同时却又缺额发对于 AI 可解释性和安全的思考——这就是深度学习领域的现状。<strong></strong><p></p><p>Dario Amodei 接受媒体采访时就曾直言，AI 研究人员应该开发更安全的系统，而不是执迷于 " 放卫星 " 似的，盲目开发参数量越来越大的神经网络。</p><p>——这基本就是在对 OpenAI 隔空喊话：你们已经忘记了初心。</p><p>今天的 OpenAI 已经不再是一家纯粹的非营利研究机构了，而是基本成为了商业公司。但好在，它似乎也已痛定思痛，认清了模型越大偏见越大的问题，并且也看到了这种超大模型应用于商业场景时带来的极大社会风险，所以加紧对 GPT-3 进行可控、可解释，以及安全方面的优化，带来了今天的 InstructGPT 模型。</p><p>OpenAI 首席科学家，AI 大神 Ilya Sutskever 表示：" 我们很兴奋地看到客户也更青睐这些对齐模型（即 InstructGPT），这意味着我们有更多的激励来开发和完善此类模型。"</p><p>* 注：题图来自于 Pixabay/Protocol ，版权属于原作者。如果不同意使用，请尽快联系我们，我们会立即删除。</p><div id="recommend_bottom"></div><div id="article_bottom"></div>  
</div>
            