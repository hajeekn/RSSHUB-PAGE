
---
title: '2D图片_脑补_3D 这次真的只用一张图就行了'
categories: 
 - 新媒体
 - 快科技（原驱动之家）
 - 最新新闻
headimg: 'https://img1.mydrivers.com/img/20220302/Scc2795c9-6ddd-4832-99c8-4c19248127f3.png'
author: 快科技（原驱动之家）
comments: false
date: Wed, 02 Mar 2022 14:06:39 GMT
thumbnail: 'https://img1.mydrivers.com/img/20220302/Scc2795c9-6ddd-4832-99c8-4c19248127f3.png'
---

<div>   
<p>2D图片“脑补”3D模型，这次真的只用一张图就行了——</p>
<p>只需要给AI随便喂一张照片，它就能从不一样的角度给你生成“新视图”：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/cc2795c9-6ddd-4832-99c8-4c19248127f3.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="166" src="https://img1.mydrivers.com/img/20220302/Scc2795c9-6ddd-4832-99c8-4c19248127f3.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>不仅能搞定360°的椅子和汽车，连人脸也玩出了新花样，从“死亡自拍”角度到仰视图都能生成：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/451f5a1b-13ad-47ff-8047-c4f46a020932.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="270" src="https://img1.mydrivers.com/img/20220302/S451f5a1b-13ad-47ff-8047-c4f46a020932.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>更有意思的是，这只名叫Pix2NeRF的AI，连训练用的数据集都有点“与众不同”，可以在没有3D数据、多视角或相机参数的情况下学会生成新视角。</p>
<p>可以说是又把NeRF系列的AI们卷上了一个新高度。</p>
<p><strong>用GAN+自动编码器学会“脑补”</strong></p>
<p>在此之前，NeRF能通过多视图训练AI模型，来让它学会生成新视角下的3D物体照片。</p>
<p>然而，这也导致一系列采用NeRF方法的模型，包括PixelNeRF和GRF，都需要利用多视图数据集才能训练出比较好的2D生成3D模型效果。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/f4fbe1b2-24df-42dc-963f-70e3b3a089c2.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="278" src="https://img1.mydrivers.com/img/20220302/Sf4fbe1b2-24df-42dc-963f-70e3b3a089c2.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>而多视图数据集往往有限，训练时间也比较长。</p>
<p>因此，作者们想出了一个新方法，也就是用自动编码器来提取物体姿态和形状特征，再用GAN直接生成全新的视角图片。</p>
<p>Pix2NeRF包含三种类型的网络架构，即生成网络G，判别网络D和编码器E。</p>
<p>其中，生成网络G和判别网络D组成生成对抗网络GAN，而编码器E和生成网络G用于构成自动编码器：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/8037ac68-0752-4a13-9081-07abc2dfa205.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="149" src="https://img1.mydrivers.com/img/20220302/S8037ac68-0752-4a13-9081-07abc2dfa205.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>首先，自动编码器可以通过无监督学习，来获取输入图像的隐藏特征，包括物体姿态和物体形状，并利用学习到的特征重建出原始的数据；</p>
<p>然后，再利用GAN来通过姿态和形状数据，重构出与原来的物体形状不同的新视图。</p>
<p>这里研究人员采用了一种叫做π-GAN的结构，生成3D视角照片的效果相比其他类型的GAN更好（作者们还对比了采用HoloGAN的一篇论文）：</p>
<p style="text-align: center"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="199" src="https://img1.mydrivers.com/img/20220302/c84d607c-dc93-49dd-b41a-fbd8a617ce16.jpg" style="border: black 1px solid" w="480" referrerpolicy="no-referrer"></p>
<p>那么，这样“混搭”出来的AI模型，效果究竟如何？</p>
<p><strong>用糊图也能生成新视角</strong></p>
<p>作者们先是进行了一系列的消融实验，以验证不同的训练方法和模型架构，是否真能提升Pix2NeRF的效果。</p>
<p>例如，针对模型去掉GAN逆映射、自动编码器，或不采用warmup针对学习率进行预热等，再尝试生成新视角的人脸：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/a28017e7-d472-407b-8e10-f02df39f9ff7.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="420" src="https://img1.mydrivers.com/img/20220302/Sa28017e7-d472-407b-8e10-f02df39f9ff7.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>其中，GAN逆映射（inversion）的目的是将给定的图像反转回预先训练的GAN模型的潜在空间中，以便生成器从反转代码中重建图像。</p>
<p>实验显示，除了完整模型（full model）以外，去掉各种方法的模型，生成人脸的效果都不够好。</p>
<p>随后，作者们又将生成照片的效果与其他生成新视图的AI模型进行了对比。</p>
<p>结果表明，虽然Pix2NeRF在ShapeNet-SRN的生成效果上没有PixelNeRF好，但效果也比较接近：</p>
<p style="text-align: center"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="506" src="https://img1.mydrivers.com/img/20220302/04045b68-d16c-44fc-a594-a55dc412803a.png" style="border: black 1px solid" w="468" referrerpolicy="no-referrer"></p>
<p>而在CelebA和CARLA数据集上，Pix2NeRF基本都取得了最好的效果。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/56cb08cd-e4b5-47fe-973f-8d78bb57057b.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="542" src="https://img1.mydrivers.com/img/20220302/S56cb08cd-e4b5-47fe-973f-8d78bb57057b.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>而且模型还自带一些“美颜”功能，即使是糊图送进去，也能给GAN出更丝滑的轮廓：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/4ee7044c-979c-4b35-b0b1-d393f23c9e94.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="574" src="https://img1.mydrivers.com/img/20220302/S4ee7044c-979c-4b35-b0b1-d393f23c9e94.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>整体而言，除了人脸能生成不同角度的新视图以外，物体还能脑补出360°下不同姿态的效果：</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/a41e7bf9-2089-4457-9096-6dc60f0a25b2.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="486" src="https://img1.mydrivers.com/img/20220302/Sa41e7bf9-2089-4457-9096-6dc60f0a25b2.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>看来，AI也和人类一样，学会“脑补”没见过的物体形状了。</p>
<p><strong>作者介绍</strong></p>
<p>这次论文的作者均来自苏黎世联邦理工学院（ETH）。</p>
<p>论文一作Shengqu Cai，ETH硕士研究生，本科毕业于伦敦国王学院，研究方向是神经渲染、生成模型和无监督学习等，高中毕业于辽宁省实验中学。</p>
<p>Anton Obukhov，ETH博士生，此前曾在英伟达等公司工作，研究方向是计算机视觉和机器学习。</p>
<p>Dengxin Dai，马普所高级研究员和ETH（外部）讲师，研究方向是自动驾驶、传感器融合和有限监督下的目标检测。</p>
<p>Luc Van Gool，ETH计算机视觉教授，谷歌学术上的引用量达到15w+，研究方向主要是2D和3D物体识别、机器人视觉和光流等。</p>
<p>目前这项研究的代码还在准备中。</p>
<p style="text-align: center"><a href="https://img1.mydrivers.com/img/20220302/7ba1f474-1f98-4fcf-bf0f-dc2f3ed8f5a9.png" target="_blank"><img alt="2D图片“脑补”3D 这次真的只用一张图就行了" h="114" src="https://img1.mydrivers.com/img/20220302/S7ba1f474-1f98-4fcf-bf0f-dc2f3ed8f5a9.png" style="border: black 1px solid" w="600" referrerpolicy="no-referrer"></a></p>
<p>感兴趣的小伙伴可以蹲一波了~</p>
<p>论文地址：https://arxiv.org/abs/2202.13162</p>
<p>项目地址：https://github.com/sxyu/pixel-nerf</p>
<p>参考链接：</p>
<p>[1]https://arxiv.org/pdf/2102.03285.pdf</p>
<p>[2]https://arxiv.org/pdf/2012.02190.pdf</p>
<p>[3]https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning</p>
<p>[4]https://www.linkedin.com/in/shengqu-cai-818230185/</p>

           
           
<p class="end"><img src="https://icons.mydrivers.com/news/end_article.png" referrerpolicy="no-referrer"></p> 
<div style="overflow: hidden;font-size:14px;">
             
          <p class="url"><span style="color:#666">责任编辑：随心</span><a href="javascript:;" class="jiucuo" id="leftjiucuo">文章纠错</a></p>
        </div>
        <div class="page_article" id="bnext">
 
</div>
<p class="bqian">话题标签：<a href="https://news.mydrivers.com/tag/3d.htm">3D</a><a href="https://news.mydrivers.com/tag/tupian.htm">图片</a><a href="https://news.mydrivers.com/tag/sanwei.htm">三维</a>  </p>
        
</div>
            