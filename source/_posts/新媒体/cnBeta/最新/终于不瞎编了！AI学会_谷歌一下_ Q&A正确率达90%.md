
---
title: '终于不瞎编了！AI学会_谷歌一下_ Q&A正确率达90%'
categories: 
 - 新媒体
 - cnBeta
 - 最新
headimg: 'https://static.cnbetacdn.com/thumb/article/2022/0318/aad38a4036a312c.png'
author: cnBeta
comments: false
date: Fri, 18 Mar 2022 07:17:56 GMT
thumbnail: 'https://static.cnbetacdn.com/thumb/article/2022/0318/aad38a4036a312c.png'
---

<div>   
语言模型总是给出“驴唇不对马嘴”的答案，已经成为它最饱受诟病的问题之一。现在，DeepMind想到了一个解决办法——让模型像人类一样，学会“Google一下”，回答问题同时还能给出 <strong>论据</strong>。<br>
 <p><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0318/aad38a4036a312c.png"><img data-original="https://static.cnbetacdn.com/article/2022/0318/aad38a4036a312c.png" src="https://static.cnbetacdn.com/thumb/article/2022/0318/aad38a4036a312c.png" referrerpolicy="no-referrer"></a><br></p><p>这个模型名叫 <strong>GopherCite</strong>，当你问它：</p><blockquote><p>GopherCite是如何找到论据来源的？</p></blockquote><p>它会回答：</p><blockquote><p>通过Google搜索检索相关文档。</p></blockquote><p>同时还给出了答案的依据，援引自DeepMind发布这项研究的页面。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0318/6e08ceaf35531bc.png"><img data-original="https://static.cnbetacdn.com/article/2022/0318/6e08ceaf35531bc.png" src="https://static.cnbetacdn.com/thumb/article/2022/0318/6e08ceaf35531bc.png" referrerpolicy="no-referrer"></a><br></p><p>而且遇到实在不懂的问题，它还会说“I don’t know.”，不会强行给一个错误答案。</p><p>训练结果显示，该模型在自然问题数据集、ELI5数据集上的正确率分别可以达到 <strong>90%</strong>、 <strong>80%</strong>，接近人类水平。</p><p>用强化学习训练AI查Google</p><p>首先我们来看一下GopherCite的效果如何。</p><p>当被问道：</p><blockquote><p>在Scooby Doo中，Scooby是什么动物？</p></blockquote><p>GopherCite回答道：</p><blockquote><p>一只大丹犬。</p><p>摘自维基百科Scooby-Doo。这是周六早上播出的系列青少年动画片，主角包括弗雷德·琼斯等，以及一只名叫Scooby-Doo、会说话的大丹犬。</p></blockquote><p><img src="https://static.cnbetacdn.com/article/2022/0318/d75f064a8ed7cdb.png" referrerpolicy="no-referrer"><br></p><p>不难看出，在学会找论据后，AI给出的回答靠谱多了。</p><p>事实上，GopherCite的前辈——超大语言模型Gopher，此前回答问题时的表现就要差劲很多。</p><p><strong>Gopher</strong>是DeepMind在去年年底发布的NLP模型，包含2800亿参数。</p><p>它基于Transformer架构，在10.5TB大小的MassiveText语料库上进行训练。</p><p>在这里，DeepMind举了一个例子来说明。</p><p>让Gopher和GopherCite回答同一个问题：</p><blockquote><p>普莱西德湖一共举办过几次冬奥会？</p></blockquote><p>Gopher回答 （是错的）：</p><blockquote><p>普莱西德湖在1932年、1936年、1980年举办过冬奥会。</p></blockquote><p>但GopherCite就答对了：</p><blockquote><p>两次。</p></blockquote><p>并给出了严谨的理由：</p><blockquote><p>援引自美国主办奥运会城市史。1932年、1980年在普莱西德湖举办过冬季奥运会；1936年、1984年在洛杉矶举办过夏季奥运会。</p></blockquote><p><img src="https://static.cnbetacdn.com/article/2022/0318/3d7f52cc633db82.png" referrerpolicy="no-referrer"><br></p><p>那么GopherCite的具体工作原理是怎样的呢？</p><p>在Gopher的基础上，研究人员开发了一种奖励机制，也就是用上 <strong>强化学习</strong>。</p><p>在收到问题后，模型会访问Google搜索的API来找到相关的网页，获取top-K结果。</p><p>（top-K操作，即从分数集合中找到k个最大或最小元素，是一个重要的机器学习模型组件，被广泛用于信息检索和数据挖掘中。）</p><p>然后它会根据问题来生成一些答案，答案数量N会大于K。</p><p>这些答案同时会带有自己的证据，即从网页上搜索到的包含答案的文段。</p><p>接下来，系统会对这些答案进行打分，最终输出 <strong>得分最高</strong>的答案。</p><p>在推理过程中，模型采样会按照循环在文档上不断迭代，每个循环都会从单个文档中尽可能多地显示上下文内容，然后对文本重新排序并返回给上一步。</p><p>此外，这个模型还会计算最终生成答案的质量，如果生成答案太差，它就会选择不回答。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0318/f21e6ec8f71938d.png"><img data-original="https://static.cnbetacdn.com/article/2022/0318/f21e6ec8f71938d.png" src="https://static.cnbetacdn.com/thumb/article/2022/0318/f21e6ec8f71938d.png" referrerpolicy="no-referrer"></a><br></p><p>这是源于红牛的广告语：“它会给你翅膀”。</p><p>在ELI5Filtered数据集上回答70%的问题时，正确率为80%左右。</p><p>DeepMind表示这种训练模式和 <strong>L<a data-link="1" href="https://c.duomai.com/track.php?site_id=242986&euid=&t=https://amd-cpu.jd.com/" target="_blank">AMD</a>A</strong>有些类似。</p><p>LaMDA是Google在去年I/O大会上发布的一个对话模型，它能够在“听懂”人类指令的基础上，对答如流并保证逻辑、事实正确。</p><p><img src="https://p9.itc.cn/q_70/images03/20220318/53a072382a1941a985cfd84e1db218e3.gif" referrerpolicy="no-referrer"><br></p><p>不同的是，LaMDA有时会直接给人分享问题的相关链接，而GopherCite可以直接摘出相关论据文段。</p><p>另外，OpenAI最近也开发了一个 <strong>网页版GPT</strong>（WebGPT），同样也是用类似的方法来校正GPT-3。</p><p>DeepMind表示，WebGPT是通过多次访问网页来组织答案，GopherCite则是侧重于读取长文段。</p><p>还是会有失误</p><p>虽然懂得援引资料了，但是GopherCite有时还是会生搬硬套。</p><p>比如当你问它“喝了红牛会怎么样？”，它的回答是“ <strong>翅膀</strong>”。</p><p><a target="_blank" href="https://static.cnbetacdn.com/article/2022/0318/f37190ff79f1ab9.png"><img data-original="https://static.cnbetacdn.com/article/2022/0318/f37190ff79f1ab9.png" src="https://static.cnbetacdn.com/thumb/article/2022/0318/f37190ff79f1ab9.png" referrerpolicy="no-referrer"></a><br></p><p>这是源于红牛的广告语：“它会给你翅膀”。</p><p>显然让它理解比喻还是有点困难……</p><p>也有网友吐槽说，可能人类自己去Google搜索会更快。</p><p>你觉得呢？</p><p>参考资料：</p><p><a href="https://deepmind.com/research/publications/2022/GopherCite-Teaching-Language-Models-To-Support-Answers-With-Verified-Quotes" _src="https://deepmind.com/research/publications/2022/GopherCite-Teaching-Language-Models-To-Support-Answers-With-Verified-Quotes" target="_blank">https://deepmind.com/research/publications/2022/GopherCite-Teaching-Language-Models-To-Support-Answers-With-Verified-Quotes</a><br></p>   
</div>
            