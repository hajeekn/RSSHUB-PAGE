
---
title: '梁正：算法治理应关注技术使用过程及产生的影响'
categories: 
 - 新媒体
 - 趣头条
 - 分类
headimg: 'https://picsum.photos/400/300?random=5961'
author: 趣头条
comments: false
date: Tue, 21 Dec 2021 08:16:07 GMT
thumbnail: 'https://picsum.photos/400/300?random=5961'
---

<div>   
<p> 中新经纬12月21日电 (薛宇飞)近日，清华大学社会科学学院社会学系、中国科学院学部-清华大学科学与社会协同发展研究中心主办了“伦理立场、算法设计与企业社会责任”研讨会。清华大学公共管理学院教授、人工智能治理研究中心主任梁正在研讨会上表示，算法治理是一个制度问题，不是技术问题，算法的治理应当重点关注算法使用的过程及其产生的影响。</p><p> 梁正表示，从技术特性方面看，机器学习目前还是一个“黑箱”过程，在透明性和可解释性上存在问题，某种程度上类似于化学科学产生之前的“炼金术”阶段，“我们知道算法管用，但不知道它的核心原理是什么，需要在基础理论方面进一步深入研究。”</p><p> 梁正分析说，从国际经验看，欧盟是自上而下地制定规则，以算法透明和问责去保证算法公平。他称，这里面，涉及到了算法原理的可解释性、过程的可追溯性及决策结果的可被理解性，具体的治理路径是建立算法评估机制、审计机制以及问责机制，用这个方式倒推算法开发和应用的责任。</p><p> 相较而言，美国对算法的规制相对谨慎，梁正说，“如果把算法理解为一套技术方案，对它进行干预的话，可能就不符合基本的市场竞争理念。美国在这方面还是很小心，特别是商业、企业领域。不过，在过去三年，美国在公共领域比较明显的变化是对人脸识别技术的禁用，包括纽约市出台的算法问责法，州层面出台的法案如《加州消费者隐私法》，则类似于欧盟的思路。”</p><p> 他介绍，中国目前已经出台一系列法律法规，包括《中华人民共和国网络安全法》《中华人民共和国数据安全法》《中华人民共和国个人信息保护法》，建立了基础机制，一些规范、指引、准则在推出过程中，数据治理体系也在建设中。在基本的制度体系建立后，接下来应该重点研究制定可实施和操作的细则。</p><p> “治理模式构建方面，算法的治理不在于算法本身，而在于算法使用后产生的影响。当然，也不只是看结果，还要看过程，这是一个理想状况。如果技术解决方案上能够做到可解释、可负责、可信任，就可以保障它不出问题。算法治理还需要多方协同参与，包括使用者、劳动者、研发设计者、管理者等等。”他还说。</p><p> 梁正指出，“目前国家出台的相关法律，把安全、个人权益等敏感问题的红线都划出来了，之后便是针对各专门应用领域提出更具体的要求，算法做到可解释、可问责，治理中实现分级分类、分场景。同时，过程中有监督，事后有补救，以及确定治理的优先级，在不同领域应用不同的治理工具，包括对基本底线的把控。”</p><p> 他最后强调，算法治理是一个制度问题，不是技术问题，不能仅仅按照技术的选择区分什么是好算法或坏算法。(中新经纬APP)</p><p> <strong>中新经纬版权所有，未经书面授权，任何公司及个人不得转载、摘编或以其它方式使用。</strong></p>  
</div>
            